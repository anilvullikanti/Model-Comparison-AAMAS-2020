\section{Introduction}

%%\begin{itemize}
%%    \item Complex large-scale agent-based models are becoming more common, in several application areas.
%%    \item These models are data-driven and specific, customized to answer specific questions or model specific phenomena.
%%    \item Often, we see multiple models for the same general phenomenon, such as epidemic spread, technology adoption, disaster evacuation, etc., created with different parameters, data sources, and model structure.
%%    \item This raises the general question of how to compare such models~\cite{axtell96aligning,burton99validation}.
%%    \item For example, in the case of the adoption of rooftop solar panels by households in two different parts of the country, we might wish to know whether it is somehow easier to have a large number of adoptions in one region than another, or whether it is just a chance difference.
%%    \item In this paper, we present a general framework to make these types of model comparisons. Then we present a specific example of the application of this framework to the comparison of two different models of the adoption of rooftop solar panels by households in two different regions of the United States.
%%    \item The rest of this paper is organized as follows. First we present the general methodological framework. Then we describe the two models we are comparing. In this specific case, model comparison requires learning a phase transition boundary in a contagion model. However, since the agent-based simulations are expensive (time-consuming) to run, we develop an active learning method with the simulation in the loop. After describing this method in detail, we present results from computational experiments with the two models. We end with a discussion of related work and future directions.
%%\end{itemize}

Complex large-scale agent-based models (ABM) are becoming increasingly common, in a huge number of application areas,
such as public health \cite{epi}, infrastructure systems such as transportation and power, disaster evacuation, and
technology adoption.
ABMs are designed to answer specific questions within an application, and their design is data-driven.
As a result, there can be multiple ABMs with a similar overall structure, but differences in the
specific model components, their interactions and parameters.
This raises the general question of how to compare such models~\cite{axtell96aligning,burton99validation}.
Axtell et al.~\cite{axtell96aligning} were the first to address this question, and developed the ``docking'' technique,
which involves verifying whether or not the dynamical properties of one ABM can be regenerated by another.
However, this is computationally intractable as ABMs become complex, and a very restrictive notion.
This question is analogous to phase space equivalence of dynamical systems \cite{ref}.

In this paper, we present a general and more scalable framework to make these types of comparisons between ABMs.
Then we present a specific example of the application of this framework to the comparison of two different 
models of the adoption of rooftop solar panels by households in two different regions of the United States.
A question of interest for local governments and utilities is to
understand who will adopt solar, and how to increase adoption.
We compare two different ABMs, one developed for California \cite{zhang16solar},
and the other for Virginia~\cite{hu19rooftop}. The probability of adoption by a household depends on a number of factors,
including demographics and characteristics of the house, as well as \emph{peer effects}, captured by the number of
households who have adopted within a 1-4 mile range. The two models have a large fraction of common factors,
but some which are distinct, e.g., pool ownership, which is a factor in the ABM of~\cite{zhang16solar},
but not in that of~\cite{hu19rooftop}. The datasets used in the calibration of these two ABMs have different
characteristics, with a much larger adoption rate in California.
In order to compare these two ABMs, we study whether it is somehow easier to have a large number of adoptions 
in one region than another, or whether it is just a chance difference. 



The rest of this paper is organized as follows. First we present the general methodological framework. Then we describe the two models we are comparing. In this specific case, model comparison requires learning a phase transition boundary in a contagion model. However, since the agent-based simulations are expensive (time-consuming) to run, we develop an active learning method with the simulation in the loop. After describing this method in detail, we present results from computational experiments with the two models. We end with a discussion of related work and future directions.
